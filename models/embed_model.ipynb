{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Transformers\n",
    "\n",
    "\n",
    "Составление эмбедингов для вопроса пользователя и поиск наиболее близкого среди всего корпуса вопросов, релевантность определяется с помощью косинусной близости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как все данные находятся в json файлах, а нам необходимо их иметь в быстро доступности, то напишем функцию, которая создает список из вопросов-ответов нашего датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_corpus_texts(json_path):\n",
    "\n",
    "    with open(fr\"{json_path}\", \"r\") as read_file:\n",
    "        texts = json.load(read_file)\n",
    "        \n",
    "    qa_sentences = set()\n",
    "    paragraphs = texts[\"data\"][0][\"paragraphs\"]\n",
    "    \n",
    "    for context in paragraphs:\n",
    "        qas = context[\"qas\"]\n",
    "        for qa in qas:\n",
    "            qa_sentences.add(qa[\"question\"] + \" \" + qa[\"answers\"][0][\"text\"])\n",
    "    \n",
    "    return list(qa_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings with Sentence Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[HuggingFace](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruagyk6/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model_sentence_transformer = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Не зачлись часы с карточки, хотя пришло сообщение от бота, что делать?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine-Similarity: tensor([[0.7633]])\n"
     ]
    }
   ],
   "source": [
    "emb1 = model_sentence_transformer.encode(\"Не зачислены часы в кабинет, с карточек, которые помечены как выполненные, что делать? обратитесь к оператору техподдержки\")\n",
    "emb2 = model_sentence_transformer.encode(question)\n",
    "cos_sim = util.cos_sim(emb1, emb2)\n",
    "print(\"Cosine-Similarity:\", cos_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиск близкой пары вопрос-ответ во всей базе знаний"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute cosine similarity between question and all corpus of texts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['нет доступа на добавление новых колонок и дорожек в wekan доске проекта Для решения Вашей проблемы, пожалуйста, обратитесь к оператору техподдержки в следующих каналах zulip: техническая поддержка миэм и проектный офис..',\n",
       " 'по ошибке зачел лишние часы себе и александре. возможно ли как-то исправить или мне лучше потом в дальнейших карточках взаимозачет часов произвести? Удалить их не получится, можете сделать дальнейший взаимозачет часов.',\n",
       " 'возникает ошибка при входе в проектный cabinet, что делать? Для решения Вашей проблемы, пожалуйста, обратитесь к оператору техподдержки в следующих каналах zulip: техническая поддержка миэм и проектный офис.',\n",
       " 'в wekan не доступна кнопка добавления участников +. как исправить? Для решения Вашей проблемы, пожалуйста, обратитесь к оператору техподдержки в следующих каналах zulip: техническая поддержка миэм и проектный офис.',\n",
       " 'долго висит комната в jitsi, вечная загрузка, что делать? Для решения Вашей проблемы, обратитесь в техподдержку, а также необходимо проверить Вашу аватарку для аккаунта: из-за того что у гугла последнее время проблемы с кэшем в россии, то запрос картинок висит очень долго и падает в итоге с ошибкой. а библиотека jitsi написана так, что пока запрос аватарки не пройдет, то он дальше просто не идет. зайдите в профиль ВШЭ https://lk.hse.ru/profile и загрузите себе аватарку. В https://meet.miem.hse.ru/ сделайте выход из профиля, а затем авторизуйтесь через елк ВШЭ.',\n",
       " 'я руководитель и не могу проставить часы в карточках на доске wekan, что делать? Для решения Вашей проблемы, пожалуйста, для решения Вашей проблемы, пожалуйста, обратитесь к оператору техподдержки в следующих каналах zulip: техническая поддержка миэм и проектный офис. в следующих каналах zulip: Техническая поддержка МИЭМ и Проектный офис.',\n",
       " 'засчитали лишние часы, как исправить? Удалить их не получится, можете сделать дальнейший взаимозачет часов.',\n",
       " 'влияют ли коммиты в архивный репозиторий на статистику в cabinet? Не влияют на статистику проекта.',\n",
       " 'как создать в вики страничку для проекта? Для решения Вашей проблемы, пожалуйста, для решения Вашей проблемы, пожалуйста, обратитесь к оператору техподдержки в следующих каналах zulip: техническая поддержка миэм и проектный офис. в следующих каналах zulip: Техническая поддержка МИЭМ и Проектный офис.',\n",
       " \"при отправке карточек какие-то не зачлись, высветилась ошибка отправки часов, что делать? Попросите руководителя убрать из названий тех карточек, которые не зачлись, значок кавычек.потом ему нужно будет убрать и заново проставить галочку 'выполнено'.после этого часы будут отправлены в cabinet\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts = extract_corpus_texts(\"./train-v1.1.json\")\n",
    "test_texts = extract_corpus_texts(\"./dev-v1.1.json\")\n",
    "sentences = train_texts + test_texts\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4574, 0.6394, 0.5116, 0.4688, 0.4505, 0.4290, 0.7476, 0.4809, 0.3390,\n",
       "         0.5120, 0.3991, 0.5806, 0.4631, 0.4795, 0.6038, 0.5648, 0.4250, 0.6633,\n",
       "         0.4187, 0.3746, 0.4358, 0.4763, 0.5856, 0.4976, 0.6770, 0.6643, 0.4871,\n",
       "         0.6802, 0.4020, 0.6543, 0.5030, 0.5724, 0.4303, 0.3598, 0.4490, 0.5570,\n",
       "         0.4520, 0.3732, 0.4154, 0.5904, 0.6124, 0.4562, 0.3688, 0.5018, 0.6541,\n",
       "         0.5131, 0.4219, 0.7143, 0.3546, 0.4021, 0.3799, 0.2714, 0.3043, 0.2957,\n",
       "         0.5439, 0.5583, 0.5634, 0.4650, 0.6496, 0.6416, 0.4203, 0.5465, 0.6141,\n",
       "         0.6194, 0.4337, 0.3864, 0.6738, 0.5977, 0.5010, 0.5787, 0.4293, 0.4579,\n",
       "         0.6528, 0.4830, 0.4715, 0.5386, 0.6156, 0.5509, 0.5090, 0.5805, 0.5532,\n",
       "         0.4261, 0.4162, 0.2450, 0.4423, 0.6503, 0.4044, 0.6103, 0.5720, 0.4571,\n",
       "         0.7075, 0.6886, 0.4038, 0.4797, 0.4774, 0.6014, 0.4754, 0.5535, 0.4627,\n",
       "         0.5839, 0.3924, 0.4448, 0.6149, 0.6019, 0.4570, 0.4104, 0.5469, 0.6199,\n",
       "         0.5389, 0.4764, 0.4113, 0.6107, 0.7183, 0.4561, 0.6773, 0.4141, 0.4252,\n",
       "         0.3627, 0.5536, 0.5819, 0.2958, 0.3104, 0.4583, 0.5275, 0.6083, 0.5042,\n",
       "         0.4268, 0.4821, 0.5058, 0.5843, 0.3766, 0.6791, 0.4026, 0.5712, 0.3425,\n",
       "         0.5774, 0.4197, 0.5417, 0.6947, 0.4164, 0.4640, 0.3201, 0.3632, 0.5673,\n",
       "         0.4332, 0.4478, 0.5405, 0.6107, 0.7561, 0.3122, 0.5169, 0.4459, 0.3141,\n",
       "         0.5558, 0.4435, 0.4965, 0.4493, 0.3820, 0.5796, 0.3167, 0.6068, 0.4700,\n",
       "         0.5275, 0.5634, 0.6337, 0.4121, 0.4138, 0.4395, 0.3057, 0.5393, 0.3935,\n",
       "         0.4884, 0.5256, 0.4810, 0.3861, 0.3303, 0.4363, 0.4908, 0.4600, 0.7227,\n",
       "         0.5085, 0.5404, 0.5002, 0.5992, 0.5118, 0.1573, 0.6543, 0.5286, 0.3845,\n",
       "         0.5460, 0.6153, 0.3909, 0.4986, 0.6662, 0.4389, 0.3161, 0.5663, 0.4107,\n",
       "         0.5219, 0.5654, 0.4149, 0.5443, 0.5317, 0.4256, 0.5346, 0.4776, 0.5196,\n",
       "         0.5730, 0.4854, 0.6229, 0.6006, 0.5784, 0.5295, 0.4278, 0.3871, 0.3338,\n",
       "         0.4073, 0.5766, 0.4924, 0.4418, 0.7171, 0.4820, 0.5423, 0.5673, 0.6654,\n",
       "         0.3888, 0.6347, 0.5301, 0.6773, 0.5481, 0.4500, 0.5338, 0.4171, 0.5150,\n",
       "         0.4535, 0.5924, 0.4811]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encode all sentences\n",
    "embeddings = model_sentence_transformer.encode(sentences)\n",
    "embebbidng_question = model_sentence_transformer.encode(question)\n",
    "\n",
    "#Compute cosine similarity between all pairs\n",
    "cos_sim = util.cos_sim(embebbidng_question, embeddings)\n",
    "\n",
    "cos_sim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find top-1 embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(148)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'хочу продлить свой проект на следующий год, но не получается, что делать? Вам необходимо обратиться в проектный офис.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_max = cos_sim.argmax()\n",
    "print(ind_max)\n",
    "sentences[ind_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find top-3 embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148   6 179]\n",
      "['хочу продлить свой проект на следующий год, но не получается, что делать? Вам необходимо обратиться в проектный офис.', 'засчитали лишние часы, как исправить? Удалить их не получится, можете сделать дальнейший взаимозачет часов.', 'хочу удалить зачтенную карточку из wekan, что делать? Этого сделать нельзя, можно лишь исправить неправильно зачтенную карточку.']\n"
     ]
    }
   ],
   "source": [
    "index_top3 = np.argsort(cos_sim.numpy())[0][::-1][:3]\n",
    "print(index_top3)\n",
    "top3_embeddings = [sentences[index] for index in index_top3]\n",
    "print(top3_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Напишем функции для поиска контекста по вопросу***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relevant_context_cosine(sentence_transformer, question, sentences, top=1):\n",
    "    #Encode all sentences\n",
    "    embeddings = sentence_transformer.encode(sentences)\n",
    "    embebbidng_question = sentence_transformer.encode(question)\n",
    "\n",
    "    #Compute cosine similarity between all pairs\n",
    "    cos_sim = util.cos_sim(embebbidng_question, embeddings)\n",
    "        \n",
    "    if top == 1:\n",
    "        ind_max = cos_sim.argmax()\n",
    "        cos_max = cos_sim.max()\n",
    "        return cos_max, sentences[ind_max]\n",
    "    else:\n",
    "        # find top-n embedding\n",
    "        index_top_n = np.argsort(cos_sim.numpy())[0][::-1][:top]\n",
    "        cos_top_n = np.sort(cos_sim.numpy())[0][:top]\n",
    "        return cos_top_n, [sentences[index] for index in index_top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relevant_context_semantic(sentence_transformer, question, sentences, top=1):\n",
    "    #Encode all sentences\n",
    "    embeddings = sentence_transformer.encode(sentences)\n",
    "    embebbidng_question = sentence_transformer.encode(question)\n",
    "\n",
    "    #Compute cosine similarity between all pairs\n",
    "    relevant_texts = util.semantic_search(embebbidng_question, embeddings, top_k=top)[0]\n",
    "    \n",
    "    relevant_sentences = []\n",
    "    for i in range(top):\n",
    "        id = relevant_texts[i][\"corpus_id\"]\n",
    "        relevant_sentences.append(sentences[id])\n",
    "        \n",
    "    return relevant_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Тестирование на пуле вопросов***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"Нет доступа к доске в векане, как исправить?\",\n",
    "    \"Ошибка зачисления часов в кабинет?\",\n",
    "    \"Некоторые участники проекта не видят доску в векане, что делать?\",\n",
    "    \"Руководитель не может зачесть часы с карточек?\",\n",
    "    \"Не отображается доска проекта в wekan\",\n",
    "    \"Не могу зайти в викан, авторизовался через miem почту\",\n",
    "    \"Надо добавить участников проекта на доску в векане, как это сделать?\",\n",
    "    \"Не могу авторизоваться в гитлабе, выдает ошибку, как это исправить?\",\n",
    "    \"Проблема с зачислением часов в статистику проекта в кабинете, что делать?\",\n",
    "    \"Не пришли часы из тайги?\",\n",
    "    \"Как решить проблему с двойными аккаунтами?\",\n",
    "    \"Почему в статистике кабинета не отображаются коммиты?\",\n",
    "    \"Не могу загрузить файл в репозиторий проекта?\",\n",
    "    \"У моего проекта нет доски в векане, что делать?\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_words = {\n",
    "    \"wekan\": [\"векан\", \"викан\", \"викин\", \"wekan\", \"векэн\", \"WEKAN\", \"wkan\",\"векана\", \"векане\", \"викана\", \"викане\"],\n",
    "    \"gitlab\": [\"гитлаб\", \"гитлаба\", \"гитлабе\", \"гит\", \"гите\", \"гитхаб\", \"git\", \"gitlab\", \"GIT\", \"GITLAB\"],\n",
    "    \"cabinet\": [\"кабинет\", \"кабинит\", \"cabinet\", \"CABINET\", \"кабинета\", \"кабинете\"],\n",
    "    \"taiga\": [\"тайга\", \"taiga\", \"TAIGA\"],\n",
    "    \"jitsi\": [\"джитси\", \"jitsi\", \"джисти\", \"JITSI\"],\n",
    "    \"wiki\": [\"вики\", \"wiki\", \"WIKI\"],\n",
    "    \"zulip\": [\"зулип\", \"zulip\", \"ZULIP\",\"зулипа\",\"зулипе\",\"злипа\"],\n",
    "    \"ВШЭ\": [\"вышка\",  \"ниу вшэ\", \"высшая школа экономики\", \"вше\", \"вшэ\"],\n",
    "    \"miem\": [\"миэм\", \"МИЭМ\", \"миэма\", \"миэму\", \"мем\", \"мэм\", \"мием\", \"miem\", \"MIEM\", \"meim\"],\n",
    "    \"ЕЛК\": [\"ЕЛК\", \"елк\", \"екл\", \"ЕЛКа\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим с помощью косинусной близости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, \"../preproccesing/parse_jsons.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_jsons import replace_incorrect_spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Нет доступа к доске в векане, как исправить?\n",
      "Cosine value tensor(0.8313)\n",
      "Relative context: Можно Вас добавить иным способом в доску, обратитесь к оператору техподдержки\n",
      "\n",
      "Question: Ошибка зачисления часов в кабинет?\n",
      "Cosine value tensor(0.6507)\n",
      "Relative context: Для решения Вашей проблемы, пожалуйста, обратитесь к оператору техподдержки в следующих каналах zulip: техническая поддержка миэм и проектный офис..\n",
      "\n",
      "Question: Некоторые участники проекта не видят доску в векане, что делать?\n",
      "Cosine value tensor(0.8453)\n",
      "Relative context: Вас необходимо добавить на доску проекта с почты с доменом @edu.hse.ru\n",
      "\n",
      "Question: Руководитель не может зачесть часы с карточек?\n",
      "Cosine value tensor(0.7501)\n",
      "Relative context: Этого сделать нельзя, можно лишь исправить неправильно зачтенную карточку.\n",
      "\n",
      "Question: Не отображается доска проекта в wekan\n",
      "Cosine value tensor(0.7444)\n",
      "Relative context: Стараемся оперативно решить проблему.\n",
      "\n",
      "Question: Не могу зайти в викан, авторизовался через miem почту\n",
      "Cosine value tensor(0.6704)\n",
      "Relative context: Этого сделать нельзя, можно лишь исправить неправильно зачтенную карточку.\n",
      "\n",
      "Question: Надо добавить участников проекта на доску в векане, как это сделать?\n",
      "Cosine value tensor(0.8214)\n",
      "Relative context: Вас необходимо добавить на доску проекта с почты с доменом @edu.hse.ru\n",
      "\n",
      "Question: Не могу авторизоваться в гитлабе, выдает ошибку, как это исправить?\n",
      "Cosine value tensor(0.8569)\n",
      "Relative context: Проверьте корректность авторизации в системе, аккаунт, с которог авторизуетесь.\n",
      "\n",
      "Question: Проблема с зачислением часов в статистику проекта в кабинете, что делать?\n",
      "Cosine value tensor(0.7492)\n",
      "Relative context: Вы сможете проставить итоговую оценку не более, чем за 10 дней до контрольной точки - защиты.\n",
      "\n",
      "Question: Не пришли часы из тайги?\n",
      "Cosine value tensor(0.6593)\n",
      "Relative context: Проверьте, что вы прикрепили её к юзерстори, кроме того, участник, которому назначаются часы, должен быть в команде проекта в личном кабинете.\n",
      "\n",
      "Question: Как решить проблему с двойными аккаунтами?\n",
      "Cosine value tensor(0.6375)\n",
      "Relative context: За трекер задач Тайга отвечает Николай Савельев.\n",
      "\n",
      "Question: Почему в статистике кабинета не отображаются коммиты?\n",
      "Cosine value tensor(0.7745)\n",
      "Relative context: Нужно обратиться к Владимиру Башуну.\n",
      "\n",
      "Question: Не могу загрузить файл в репозиторий проекта?\n",
      "Cosine value tensor(0.5795)\n",
      "Relative context: Для решения Вашей проблемы, пожалуйста, обратитесь к оператору техподдержки в следующих каналах zulip: техническая поддержка миэм и проектный офис. и Андрею Пискунову.\n",
      "\n",
      "Question: У моего проекта нет доски в векане, что делать?\n",
      "Cosine value tensor(0.8156)\n",
      "Relative context: Вас необходимо добавить на доску проекта с почты с доменом @edu.hse.ru\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q in questions:\n",
    "    for key, value in dict_words.items():\n",
    "        if (key in q or key in replace_incorrect_spellings(q, dict_words, morph)) and key in [\"wekan\", \"cabinet\", \"gitlab\", \"jitsi\", \"project\", \"taiga\", \"wiki\"]:\n",
    "            sentences = extract_corpus_texts(f\"../data/handmade_dataset/format of deeppavlov/full/{key}.json\")\n",
    "        else:\n",
    "            continue\n",
    "    cos_value, context = find_relevant_context_cosine(model_sentence_transformer, q, sentences)\n",
    "    if cos_value < 0.5:\n",
    "        print(\"Пока что я только учусь, поэтому не могу ответить на Ваш вопрос. Пожалуйста, обратитесь в каналы технической поддержки в zulip.\")\n",
    "    else:\n",
    "        print(\"Question:\", q)\n",
    "        print(\"Cosine value\", cos_value)\n",
    "        print(\"Relative context:\", context.split(\"? \")[1], end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем метрики оценив, на сколько вопросов модель ответила правильно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [1] * len(questions)\n",
    "y_pred = [1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.7272727272727273\n",
      "Accuracy: 0.5714285714285714\n",
      "Империческая: 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score:\", f1_score(y_true, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Империческая:\", sum(y_pred) / sum(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим по семантической близости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Нет доступа к доске в векане, как исправить?\n",
      "Relative context: Не могу получить доступ к доске в викан, мой аккаунт её не видит, что делать? Можно Вас добавить иным способом в доску, обратитесь к оператору техподдержки\n",
      "\n",
      "Question: Ошибка зачисления часов в кабинет?\n",
      "Relative context: Различается количество часов в векане и кабинете, что делать? Для решения Вашей проблемы, пожалуйста, обратитесь к оператору техподдержки в следующих каналах zulip: техническая поддержка миэм и проектный офис..\n",
      "\n",
      "Question: Некоторые участники проекта не видят доску в векане, что делать?\n",
      "Relative context: У участника нет доступа к доске проекта ни с какого аккаунта, что делать? Вас необходимо добавить на доску проекта с почты с доменом @edu.hse.ru\n",
      "\n",
      "Question: Руководитель не может зачесть часы с карточек?\n",
      "Relative context: Руководитель хочет удалить зачтенную карточку, как исправить? Этого сделать нельзя, можно лишь исправить неправильно зачтенную карточку.\n",
      "\n",
      "Question: Не отображается доска проекта в wekan\n",
      "Relative context: Весь день не работает wekan? Стараемся оперативно решить проблему.\n",
      "\n",
      "Question: Не могу зайти в викан, авторизовался через miem почту\n",
      "Relative context: Хочу удалить зачтенную карточку из векана, что делать? Этого сделать нельзя, можно лишь исправить неправильно зачтенную карточку.\n",
      "\n",
      "Question: Надо добавить участников проекта на доску в векане, как это сделать?\n",
      "Relative context: У участника нет доступа к доске проекта ни с какого аккаунта, что делать? Вас необходимо добавить на доску проекта с почты с доменом @edu.hse.ru\n",
      "\n",
      "Question: Не могу авторизоваться в гитлабе, выдает ошибку, как это исправить?\n",
      "Relative context: Проблема со входом в гит, выдает ошибку, что делать? Проверьте корректность авторизации в системе, аккаунт, с которог авторизуетесь.\n",
      "\n",
      "Question: Проблема с зачислением часов в статистику проекта в кабинете, что делать?\n",
      "Relative context: Не понимаю и не могу проставить итоговую оценку за проект в личном кабинете, что делать? Вы сможете проставить итоговую оценку не более, чем за 10 дней до контрольной точки - защиты.\n",
      "\n",
      "Question: Не пришли часы из тайги?\n",
      "Relative context: Не пришли часы за задача в тайге, что делать? Проверьте, что вы прикрепили её к юзерстори, кроме того, участник, которому назначаются часы, должен быть в команде проекта в личном кабинете.\n",
      "\n",
      "Question: Как решить проблему с двойными аккаунтами?\n",
      "Relative context: Есть ли у нас сервисные аккаунты в Тайге? За трекер задач Тайга отвечает Николай Савельев.\n",
      "\n",
      "Question: Почему в статистике кабинета не отображаются коммиты?\n",
      "Relative context: Подскажите, пожалуйста, кого следует потревожить, чтобы получить токен кабинета? Нужно обратиться к Владимиру Башуну.\n",
      "\n",
      "Question: Не могу загрузить файл в репозиторий проекта?\n",
      "Relative context: Не могу зайти в одоо, что делать? Для решения Вашей проблемы, пожалуйста, обратитесь к оператору техподдержки в следующих каналах zulip: техническая поддержка миэм и проектный офис. и Андрею Пискунову.\n",
      "\n",
      "Question: У моего проекта нет доски в векане, что делать?\n",
      "Relative context: У участника нет доступа к доске проекта ни с какого аккаунта, что делать? Вас необходимо добавить на доску проекта с почты с доменом @edu.hse.ru\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q in questions:\n",
    "    for key, value in dict_words.items():\n",
    "        if (key in q or key in replace_incorrect_spellings(q, dict_words, morph)) and key in [\"wekan\", \"cabinet\", \"gitlab\", \"jitsi\", \"project\", \"taiga\", \"wiki\"]:\n",
    "            sentences = extract_corpus_texts(f\"../data/handmade_dataset/format of deeppavlov/full/{key}.json\")\n",
    "        else:\n",
    "            continue\n",
    "    context = find_relevant_context_semantic(model_sentence_transformer, q, sentences)\n",
    "    \n",
    "    print(\"Question:\", q)\n",
    "    print(\"Relative context:\", *context, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.6666666666666666\n",
      "Accuracy: 0.5\n",
      "Империческая: 0.5\n"
     ]
    }
   ],
   "source": [
    "y_true = [1] * len(questions)\n",
    "y_pred = [1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0]\n",
    "\n",
    "print(\"F1-score:\", f1_score(y_true, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Империческая:\", sum(y_pred) / sum(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиск близкой пары вопрос-ответ с помощью другой модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для данной модели также реализуем косинусный и семантический поиск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruagyk6/Library/Python/3.9/lib/python/site-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('clips/mfaq').to(device=cpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Не получается зайти в гитлаб, возможно ошибка из-за двойного аккаунта, что делать?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'corpus_id': 0, 'score': 0.7097870111465454}\n"
     ]
    }
   ],
   "source": [
    "query_embedding = model.encode(question)\n",
    "corpus_embeddings = model.encode(sentences)\n",
    "relevant_texts = util.semantic_search(query_embedding, corpus_embeddings, top_k=2)[0][0]\n",
    "print(relevant_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Не могу зайти в векан, пишет ошибку 502? это технический сбой, который скоро должен исправиться.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[relevant_texts[\"corpus_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"Нет доступа к доске в векане, как исправить?\",\n",
    "    \"Ошибка зачисления часов в кабинет?\",\n",
    "    \"Некоторые участники проекта не видят доску в векане, что делать?\",\n",
    "    \"Руководитель не может зачесть часы с карточек?\",\n",
    "    \"Не отображается доска проекта в wekan\",\n",
    "    \"Не могу зайти в викан, авторизовался через miem почту\",\n",
    "    \"Надо добавить участников проекта на доску в векане, как это сделать?\",\n",
    "    \"Не могу авторизоваться в гитлабе, выдает ошибку, как это исправить?\",\n",
    "    \"Проблема с зачислением часов в статистику проекта в кабинете, что делать?\",\n",
    "    \"Не пришли часы из тайги?\",\n",
    "    \"Как решить проблему с двойными аккаунтами?\",\n",
    "    \"Почему в статистике кабинета не отображаются коммиты?\",\n",
    "    \"Не могу загрузить файл в репозиторий проекта?\",\n",
    "    \"У моего проекта нет доски в векане, что делать?\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Косинусная близость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Нет доступа к доске в векане, как исправить?\n",
      "Cosine value tensor(0.8313)\n",
      "Relative context: Можно Вас добавить иным способом в доску, обратитесь к оператору техподдержки\n",
      "\n",
      "Question: Ошибка зачисления часов в кабинет?\n",
      "Cosine value tensor(0.6507)\n",
      "Relative context: Для решения Вашей проблемы, пожалуйста, обратитесь к оператору техподдержки в следующих каналах zulip: техническая поддержка миэм и проектный офис..\n",
      "\n",
      "Question: Некоторые участники проекта не видят доску в векане, что делать?\n",
      "Cosine value tensor(0.8453)\n",
      "Relative context: Вас необходимо добавить на доску проекта с почты с доменом @edu.hse.ru\n",
      "\n",
      "Question: Руководитель не может зачесть часы с карточек?\n",
      "Cosine value tensor(0.7501)\n",
      "Relative context: Этого сделать нельзя, можно лишь исправить неправильно зачтенную карточку.\n",
      "\n",
      "Question: Не отображается доска проекта в wekan\n",
      "Cosine value tensor(0.7444)\n",
      "Relative context: Стараемся оперативно решить проблему.\n",
      "\n",
      "Question: Не могу зайти в викан, авторизовался через miem почту\n",
      "Cosine value tensor(0.6704)\n",
      "Relative context: Этого сделать нельзя, можно лишь исправить неправильно зачтенную карточку.\n",
      "\n",
      "Question: Надо добавить участников проекта на доску в векане, как это сделать?\n",
      "Cosine value tensor(0.8214)\n",
      "Relative context: Вас необходимо добавить на доску проекта с почты с доменом @edu.hse.ru\n",
      "\n",
      "Question: Не могу авторизоваться в гитлабе, выдает ошибку, как это исправить?\n",
      "Cosine value tensor(0.8569)\n",
      "Relative context: Проверьте корректность авторизации в системе, аккаунт, с которог авторизуетесь.\n",
      "\n",
      "Question: Проблема с зачислением часов в статистику проекта в кабинете, что делать?\n",
      "Cosine value tensor(0.7492)\n",
      "Relative context: Вы сможете проставить итоговую оценку не более, чем за 10 дней до контрольной точки - защиты.\n",
      "\n",
      "Question: Не пришли часы из тайги?\n",
      "Cosine value tensor(0.6593)\n",
      "Relative context: Проверьте, что вы прикрепили её к юзерстори, кроме того, участник, которому назначаются часы, должен быть в команде проекта в личном кабинете.\n",
      "\n",
      "Question: Как решить проблему с двойными аккаунтами?\n",
      "Cosine value tensor(0.6375)\n",
      "Relative context: За трекер задач Тайга отвечает Николай Савельев.\n",
      "\n",
      "Question: Почему в статистике кабинета не отображаются коммиты?\n",
      "Cosine value tensor(0.7745)\n",
      "Relative context: Нужно обратиться к Владимиру Башуну.\n",
      "\n",
      "Question: Не могу загрузить файл в репозиторий проекта?\n",
      "Cosine value tensor(0.5795)\n",
      "Relative context: Для решения Вашей проблемы, пожалуйста, обратитесь к оператору техподдержки в следующих каналах zulip: техническая поддержка миэм и проектный офис. и Андрею Пискунову.\n",
      "\n",
      "Question: У моего проекта нет доски в векане, что делать?\n",
      "Cosine value tensor(0.8156)\n",
      "Relative context: Вас необходимо добавить на доску проекта с почты с доменом @edu.hse.ru\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q in questions:\n",
    "    for key, value in dict_words.items():\n",
    "        if (key in q or key in replace_incorrect_spellings(q, dict_words, morph)) and key in [\"wekan\", \"cabinet\", \"gitlab\", \"jitsi\", \"project\", \"taiga\", \"wiki\"]:\n",
    "            sentences = extract_corpus_texts(f\"../data/handmade_dataset/format of deeppavlov/full/{key}.json\")\n",
    "        else:\n",
    "            continue\n",
    "    cos_value, context = find_relevant_context_cosine(model_sentence_transformer, q, sentences)\n",
    "    if cos_value < 0.5:\n",
    "        print(\"Пока что я только учусь, поэтому не могу ответить на Ваш вопрос. Пожалуйста, обратитесь в каналы технической поддержки в zulip.\")\n",
    "    else:\n",
    "        print(\"Question:\", q)\n",
    "        print(\"Cosine value\", cos_value)\n",
    "        print(\"Relative context:\", context.split(\"? \")[1], end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.6666666666666666\n",
      "Accuracy: 0.5\n",
      "Империческая: 0.5\n"
     ]
    }
   ],
   "source": [
    "y_true = [1] * len(questions)\n",
    "y_pred = [1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0]\n",
    "\n",
    "print(\"F1-score:\", f1_score(y_true, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Империческая:\", sum(y_pred) / sum(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Семантическая близость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Нет доступа к доске в векане, как исправить?\n",
      "Relative context: ['Нет доски моего проекта в векане, помогите исправить? Обратитесь к оператору техподдержки']\n",
      "\n",
      "Question: Ошибка зачисления часов в кабинет?\n",
      "Relative context: ['Не пришли часы с выполненных карточек, хотя есть комментарий от бота о зачислении часов в кабинет, как исправить эту ошибку? обратитесь к оператору техподдержки']\n",
      "\n",
      "Question: Некоторые участники проекта не видят доску в векане, что делать?\n",
      "Relative context: ['Не вижу доску проекта в векане, аккаунты miem и hse синхронизированы, что делать? обратитесь к оператору техподдержки']\n",
      "\n",
      "Question: Руководитель не может зачесть часы с карточек?\n",
      "Relative context: ['Я руководитель и не могу проставить часы в карточках на доске векан, что делать? обратитесь к оператору техподдержки']\n",
      "\n",
      "Question: Не отображается доска проекта в wekan\n",
      "Relative context: ['Векан пишет ошибку доска не найдена для моего проекта, причем иногда доска появлялась, что делать? Вам необходимо авторизоваться в Wekan, используя почту с доменом @miem.hse.ru.На досках Вы числитесь именно с этой почты']\n",
      "\n",
      "Question: Не могу зайти в викан, авторизовался через miem почту\n",
      "Relative context: ['Не могу зайти в gitalb, проблемы с авторизацией? проверьте корректность авторизации в системе, аккаунт, с которог авторизуетесь.']\n",
      "\n",
      "Question: Надо добавить участников проекта на доску в векане, как это сделать?\n",
      "Relative context: ['Не вижу доску проекта в векане, аккаунты miem и hse синхронизированы, что делать? обратитесь к оператору техподдержки']\n",
      "\n",
      "Question: Не могу авторизоваться в гитлабе, выдает ошибку, как это исправить?\n",
      "Relative context: ['Хочу удалить заявку студента на попадание в проект, но выскакивает ошибка, что делать? обратитесь к оператору техподдержки']\n",
      "\n",
      "Question: Проблема с зачислением часов в статистику проекта в кабинете, что делать?\n",
      "Relative context: ['Хочу удалить заявку студента на попадание в проект, но выскакивает ошибка, что делать? обратитесь к оператору техподдержки']\n",
      "\n",
      "Question: Не пришли часы из тайги?\n",
      "Relative context: ['Не пришли часы с выполненных карточек, хотя есть комментарий от бота о зачислении часов в кабинет, как исправить эту ошибку? обратитесь к оператору техподдержки']\n",
      "\n",
      "Question: Как решить проблему с двойными аккаунтами?\n",
      "Relative context: ['Когда захожу на доску своего проекта в wekan пишет, что доска не найдена, аккаунты мием и хсе, что делать? обратитесь к оператору техподдержки']\n",
      "\n",
      "Question: Почему в статистике кабинета не отображаются коммиты?\n",
      "Relative context: ['Влияют ли коммиты в архивный репозиторий на статистику в кабинете? не влияют на статистику проекта']\n",
      "\n",
      "Question: Не могу загрузить файл в репозиторий проекта?\n",
      "Relative context: ['Не могу загрузить файлы для проекта в гитлаб, пишет ошибку лимита по объему файла, что делать? рекомендуется размещать такие файлы в виде ссылок на яндекс диск.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q in questions:\n",
    "    context = find_relevant_context_semantic(model, q, sentences)\n",
    "    print(\"Question:\", q)\n",
    "    print(\"Relative context:\", context, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ruagyk6/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pymorphy2\n",
    "from nltk.corpus import stopwords\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Загрузка стоп-слов на русском языке для фильтрации\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка предварительно обученной модели BERT\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Токенизация текста и удаление стоп-слов\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "def extract_keywords(question):\n",
    "    # Морфологический анализ каждого слова в вопросе и извлечение основы\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    words = nltk.word_tokenize(question.lower())\n",
    "    base_forms = [morph.parse(word)[0].normal_form for word in words if word.isalnum()]\n",
    "    \n",
    "    # Удаление стоп-слов из основных форм\n",
    "    keywords = [word for word in base_forms if word not in stop_words]\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "\n",
    "\n",
    "def find_most_similar_sentence(question, corpus, bert_tokenizer, bert_model):\n",
    "    # Препроцессинг вопроса и корпуса текстов\n",
    "    question = \"[CLS] \" + question + \" [SEP]\"\n",
    "    tokenized_question = bert_tokenizer.tokenize(question)\n",
    "    tokenized_corpus = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in corpus]\n",
    "    \n",
    "    # Преобразование текста в индексы BERT-токенов\n",
    "    indexed_tokens = bert_tokenizer.convert_tokens_to_ids(tokenized_question)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    \n",
    "    # Получение эмбеддингов для вопроса\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(tokens_tensor)\n",
    "        question_embedding = torch.mean(outputs.last_hidden_state, dim=1).squeeze().numpy()\n",
    "    \n",
    "    # Вычисление косинусного сходства между вопросом и каждым предложением в корпусе\n",
    "    similarities = []\n",
    "    for sentence in tokenized_corpus:\n",
    "        # Преобразование текста в индексы BERT-токенов\n",
    "        indexed_tokens = bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize(sentence))\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        \n",
    "        # Получение эмбеддингов для предложения\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(tokens_tensor)\n",
    "            sentence_embedding = torch.mean(outputs.last_hidden_state, dim=1).squeeze().numpy()\n",
    "        \n",
    "        # Вычисление косинусного сходства между вопросом и текущим предложением\n",
    "        similarity = cosine_similarity([question_embedding], [sentence_embedding])[0][0]\n",
    "        similarities.append(similarity)\n",
    "    \n",
    "    # Нахождение индекса предложения с наибольшим значением косинусного сходства\n",
    "    most_similar_index = similarities.index(max(similarities))\n",
    "    \n",
    "    return corpus[most_similar_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Извлеченные ключевые слова из вопроса: ['зачесться', 'часы', 'карточка', 'делать']\n",
      "Наиболее близкое по смыслу предложение в корпусе текстов: Весь день не работает wekan? Стараемся оперативно решить проблему.\n"
     ]
    }
   ],
   "source": [
    "# Пример использования функций\n",
    "question = \"Не зачлись часы с карточки, что делать?\"\n",
    "\n",
    "# Извлечение ключевых слов из вопроса\n",
    "keywords = extract_keywords(question)\n",
    "\n",
    "# Поиск наиболее близкого по смыслу предложения в корпусе текстов\n",
    "most_similar_sentence = find_most_similar_sentence(question, sentences, bert_tokenizer, bert_model)\n",
    "\n",
    "print(\"Извлеченные ключевые слова из вопроса:\", keywords)\n",
    "print(\"Наиболее близкое по смыслу предложение в корпусе текстов:\", most_similar_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Нет доступа к доске в векане, как исправить?\n",
      "Cosine value tensor(0.8156)\n",
      "Relative context: это технический сбой, который скоро должен исправиться.\n",
      "\n",
      "Question: Ошибка зачисления часов в кабинет?\n",
      "Cosine value tensor(0.8156)\n",
      "Relative context: Удалить их не получится, можете сделать дальнейший взаимозачет часов.\n",
      "\n",
      "Question: Некоторые участники проекта не видят доску в векане, что делать?\n",
      "Cosine value tensor(0.8156)\n",
      "Relative context: Необходимо получить статус 'Администратор'.\n",
      "\n",
      "Question: Руководитель не может зачесть часы с карточек?\n",
      "Cosine value tensor(0.8156)\n",
      "Relative context: Стараемся оперативно решить проблему.\n",
      "\n",
      "Question: Не отображается доска проекта в wekan\n",
      "Cosine value tensor(0.8156)\n",
      "Relative context: Стараемся оперативно решить проблему.\n",
      "\n",
      "Question: Не могу зайти в викан, авторизовался через miem почту\n",
      "Cosine value tensor(0.8156)\n",
      "Relative context: Сейчас доска должна отображаться, проверьте, пожалуйста, и авторизуйтесь через ЕЛК.\n",
      "\n",
      "Question: Надо добавить участников проекта на доску в векане, как это сделать?\n",
      "Cosine value tensor(0.8156)\n",
      "Relative context: у участников, возможно, не выполнен вход в Wekan, и им следует авторизоваться через ЕЛК.Далее их можно будет добавить на доску проекта\n",
      "\n",
      "Question: Не могу авторизоваться в гитлабе, выдает ошибку, как это исправить?\n",
      "Cosine value tensor(0.8156)\n",
      "Relative context: Обратитесь к настройкам гитлаба.\n",
      "\n",
      "Question: Проблема с зачислением часов в статистику проекта в кабинете, что делать?\n",
      "Cosine value tensor(0.8156)\n",
      "Relative context: Нужно обратиться к Владимиру Башуну.\n",
      "\n",
      "Question: Не пришли часы из тайги?\n",
      "Cosine value tensor(0.8156)\n",
      "Relative context: За трекер задач Тайга отвечает Николай Савельев.\n",
      "\n",
      "Question: Как решить проблему с двойными аккаунтами?\n",
      "Cosine value tensor(0.8156)\n",
      "Relative context: За трекер задач Тайга отвечает Николай Савельев.\n",
      "\n",
      "Question: Почему в статистике кабинета не отображаются коммиты?\n",
      "Cosine value tensor(0.8156)\n",
      "Relative context: Нужно обратиться к Владимиру Башуну.\n",
      "\n",
      "Question: Не могу загрузить файл в репозиторий проекта?\n",
      "Cosine value tensor(0.8156)\n",
      "Relative context: Нужно обратиться к Владимиру Башуну.\n",
      "\n",
      "Question: У моего проекта нет доски в векане, что делать?\n",
      "Cosine value tensor(0.8156)\n",
      "Relative context: Стараемся оперативно решить проблему.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q in questions:\n",
    "    for key, value in dict_words.items():\n",
    "        if (key in q or key in replace_incorrect_spellings(q, dict_words, morph)) and key in [\"wekan\", \"cabinet\", \"gitlab\", \"jitsi\", \"project\", \"taiga\", \"wiki\"]:\n",
    "            sentences = extract_corpus_texts(f\"../data/handmade_dataset/format of deeppavlov/full/{key}.json\")\n",
    "        else:\n",
    "            continue\n",
    "    context = find_most_similar_sentence(q, sentences, bert_tokenizer, bert_model)\n",
    "\n",
    "    print(\"Question:\", q)\n",
    "    print(\"Cosine value\", cos_value)\n",
    "    print(\"Relative context:\", context.split(\"? \")[1], end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим метрики для BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.4444444444444445\n",
      "Accuracy: 0.2857142857142857\n",
      "Империческая: 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "y_true = [1] * len(questions)\n",
    "y_pred = [0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0]\n",
    "\n",
    "print(\"F1-score:\", f1_score(y_true, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Империческая:\", sum(y_pred) / sum(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сравнение bert и sentenceTransformers**\n",
    "\n",
    "Объективно, можно заметить, что поиск походящего контекст с помощь модели Bert выдает худший результат, чем SentenceTransformers. \n",
    "\n",
    "Кроме того, на такое же количество вопросов модель BERT обрабатывает в 3-4 раза медленнее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Metrics of QA](https://qa.fastforwardlabs.com/no%20answer/null%20threshold/bert/distilbert/exact%20match/f1/robust%20predictions/2020/06/09/Evaluating_BERT_on_SQuAD.html)\n",
    "- [Semantic model](https://huggingface.co/clips/mfaq)\n",
    "- [More popular semantic model](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
