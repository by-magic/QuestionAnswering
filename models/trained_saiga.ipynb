{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7700193,"sourceType":"datasetVersion","datasetId":4494766},{"sourceId":8129998,"sourceType":"datasetVersion","datasetId":4494727}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## реализация данной статьи https://habr.com/ru/articles/769124/","metadata":{"execution":{"iopub.status.busy":"2024-01-27T20:02:21.329881Z","iopub.execute_input":"2024-01-27T20:02:21.330744Z","iopub.status.idle":"2024-01-27T20:02:21.334548Z","shell.execute_reply.started":"2024-01-27T20:02:21.330710Z","shell.execute_reply":"2024-01-27T20:02:21.333729Z"}}},{"cell_type":"markdown","source":"## Новая версия","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install accelerate==0.29.2\n!pip install bitsandbytes==0.43.1\n!pip install langchain\n!pip install peft","metadata":{"execution":{"iopub.status.busy":"2024-04-16T10:32:53.070658Z","iopub.execute_input":"2024-04-16T10:32:53.070921Z","iopub.status.idle":"2024-04-16T10:34:02.613056Z","shell.execute_reply.started":"2024-04-16T10:32:53.070896Z","shell.execute_reply":"2024-04-16T10:34:02.611876Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom peft import AutoPeftModelForCausalLM\nfrom transformers import AutoTokenizer, AutoModel\nimport torch.nn.functional as F\nfrom langchain.prompts import PromptTemplate\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-16T10:34:02.615103Z","iopub.execute_input":"2024-04-16T10:34:02.615423Z","iopub.status.idle":"2024-04-16T10:34:08.619671Z","shell.execute_reply.started":"2024-04-16T10:34:02.615394Z","shell.execute_reply":"2024-04-16T10:34:08.618821Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load model from HuggingFace Hub\nsent_tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\nsent_model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T10:34:08.620655Z","iopub.execute_input":"2024-04-16T10:34:08.621042Z","iopub.status.idle":"2024-04-16T10:34:11.237905Z","shell.execute_reply.started":"2024-04-16T10:34:08.621019Z","shell.execute_reply":"2024-04-16T10:34:11.236913Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd9ff03c0f1242e5a390c82a218bc90b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e59d1f978fa94f01aae1776ae3bb1c25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dba5f6a672334d028a5fdfd56daa52e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c7720822e984c83bcf22fe7597b5cf7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b51f638eecb42e6a2586f34b5d5ad89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6f523d8d06645af8f768105c31a1bd1"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\n\npeft_model_id = \"IlyaGusev/saiga_mistral_7b_lora\"\nmodel = AutoModelForCausalLM.from_pretrained(peft_model_id, device_map=\"auto\", load_in_8bit=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T10:36:49.924253Z","iopub.execute_input":"2024-04-16T10:36:49.925132Z","iopub.status.idle":"2024-04-16T10:38:37.635540Z","shell.execute_reply.started":"2024-04-16T10:36:49.925096Z","shell.execute_reply":"2024-04-16T10:38:37.634740Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45d3fba1d0e1488880af7f060cf21dea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9c1c91f9aae4330b24e4268ddb7ea53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00002.bin:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46a9de8e4c3b4de8b74edad0a0763a8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"280744cc1bf04b83ab1d9769d8bc23ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/120 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dec812d30e38476eae8f677143ffd1ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/54.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57e6ba196cd9479e9a68ed6605313539"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(peft_model_id, trust_remote_code=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T10:55:12.249958Z","iopub.execute_input":"2024-04-16T10:55:12.250319Z","iopub.status.idle":"2024-04-16T10:55:13.816775Z","shell.execute_reply.started":"2024-04-16T10:55:12.250293Z","shell.execute_reply":"2024-04-16T10:55:13.815934Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0a44ee48b044980ba6f5286e7ea2e6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"342170ceb25b425b9bf4693c08f7450a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf5b07e53bff4ec88fca69d0a81afb8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/96.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dbc2356cccd424d8979f0359a8efca3"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\n    \nBATCH_SIZE = 4\nMICRO_BATCH_SIZE = 2\nGRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\nLEARNING_RATE = 3e-4\nTRAIN_STEPS = 50\nOUTPUT_DIR = \"/kaggle/working/tmp\"\n\ntraining_args = TrainingArguments(\n        output_dir=OUTPUT_DIR,\n        # auto_find_batch_size=True,\n        learning_rate=LEARNING_RATE,\n        num_train_epochs=TRAIN_STEPS,\n#         logging_strategy=\"steps\",\n#         logging_dir=f\"{output_dir}/logs\",\n        logging_steps=50\n    )\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T11:04:21.482371Z","iopub.execute_input":"2024-04-16T11:04:21.483122Z","iopub.status.idle":"2024-04-16T11:04:21.511516Z","shell.execute_reply.started":"2024-04-16T11:04:21.483082Z","shell.execute_reply":"2024-04-16T11:04:21.510607Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"texts = pd.read_csv(\"/kaggle/input/zulip-wekan/qa_preproc_wekan.csv\", index_col=False)\ntexts[\"qa\"] = texts.apply(lambda row: f\"<s>Вопрос: {row['question']}\\nОтвет: {row['answer']}</s>\", axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T11:04:22.260527Z","iopub.execute_input":"2024-04-16T11:04:22.260905Z","iopub.status.idle":"2024-04-16T11:04:22.283095Z","shell.execute_reply.started":"2024-04-16T11:04:22.260875Z","shell.execute_reply":"2024-04-16T11:04:22.282386Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=texts[\"qa\"],\n    tokenizer=tokenizer\n)\n\npeft_model_id = \"results\"\ntrainer.model.save_pretrained(peft_model_id)\ntokenizer.save_pretrained(peft_model_id)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T11:21:43.223719Z","iopub.execute_input":"2024-04-16T11:21:43.224132Z","iopub.status.idle":"2024-04-16T11:21:43.617926Z","shell.execute_reply.started":"2024-04-16T11:21:43.224101Z","shell.execute_reply":"2024-04-16T11:21:43.616962Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"('results/tokenizer_config.json',\n 'results/special_tokens_map.json',\n 'results/tokenizer.model',\n 'results/added_tokens.json',\n 'results/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"def get_embedding(sentence):\n    \n    #Mean Pooling - Take attention mask into account for correct averaging\n    def _mean_pooling(model_output, attention_mask):\n        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n\n    # Tokenize sentences\n    encoded_input = sent_tokenizer([sentence], padding=True, truncation=True, return_tensors='pt')\n\n    # Compute token embeddings\n    with torch.no_grad():\n        model_output = sent_model(**encoded_input)\n\n    # Perform pooling\n    sentence_embeddings = _mean_pooling(model_output, encoded_input['attention_mask'])\n\n    # Normalize embeddings\n    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n\n    return sentence_embeddings","metadata":{"execution":{"iopub.status.busy":"2024-04-16T11:20:18.799362Z","iopub.execute_input":"2024-04-16T11:20:18.800115Z","iopub.status.idle":"2024-04-16T11:20:18.807372Z","shell.execute_reply.started":"2024-04-16T11:20:18.800081Z","shell.execute_reply":"2024-04-16T11:20:18.806394Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"def get_answer(model, tokenizer, info_prompt, question):\n    # Tokenize question\n    prompt = info_prompt.format(question=question)\n    inputs = tokenizer(prompt, padding=True, truncation=True, max_length=128).input_ids.cuda()\n    # Generate output\n    \n    outputs = model.generate(input_ids=inputs, \n                            max_length=128,  # Adjust the max_length as needed\n                            pad_token_id=tokenizer.eos_token_id,\n                            do_sample=True)\n\n    # Decode outputs\n    output_decode = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n    parsed_answer = output_decode\n    return parsed_answer","metadata":{"execution":{"iopub.status.busy":"2024-04-16T11:20:22.297607Z","iopub.execute_input":"2024-04-16T11:20:22.298497Z","iopub.status.idle":"2024-04-16T11:20:22.306679Z","shell.execute_reply.started":"2024-04-16T11:20:22.298453Z","shell.execute_reply":"2024-04-16T11:20:22.305722Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"f = lambda x : ' '.join(x)\ninfo_prompt = PromptTemplate.from_template(f(texts[\"qa\"]))","metadata":{"execution":{"iopub.status.busy":"2024-04-16T11:20:28.049816Z","iopub.execute_input":"2024-04-16T11:20:28.050197Z","iopub.status.idle":"2024-04-16T11:20:28.056699Z","shell.execute_reply.started":"2024-04-16T11:20:28.050164Z","shell.execute_reply":"2024-04-16T11:20:28.055787Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"answers = []\nemb_database = torch.empty((0, 384), dtype=torch.float16)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T11:20:32.925978Z","iopub.execute_input":"2024-04-16T11:20:32.926859Z","iopub.status.idle":"2024-04-16T11:20:32.935055Z","shell.execute_reply.started":"2024-04-16T11:20:32.926824Z","shell.execute_reply":"2024-04-16T11:20:32.934052Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"question = \"Не зачислены часы в wekan\" \nemb = get_embedding(question)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T11:20:37.812171Z","iopub.execute_input":"2024-04-16T11:20:37.812511Z","iopub.status.idle":"2024-04-16T11:20:37.843798Z","shell.execute_reply.started":"2024-04-16T11:20:37.812486Z","shell.execute_reply":"2024-04-16T11:20:37.842973Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"def get_cos_sim(question):\n    cos_sim = F.cosine_similarity(emb_database, emb, dim=1, eps=1e-8)\n    return cos_sim\n  \nget_cos_sim(question)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T11:20:38.718640Z","iopub.execute_input":"2024-04-16T11:20:38.719370Z","iopub.status.idle":"2024-04-16T11:20:38.726959Z","shell.execute_reply.started":"2024-04-16T11:20:38.719335Z","shell.execute_reply":"2024-04-16T11:20:38.726018Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"tensor([])"},"metadata":{}}]},{"cell_type":"code","source":"answer = get_answer(model, tokenizer, info_prompt, question)\nemb_database = torch.cat((emb_database, emb), 0)\nanswers.append(answer)\nprint(f'Answer from model: {answer}')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T11:20:40.237172Z","iopub.execute_input":"2024-04-16T11:20:40.238041Z","iopub.status.idle":"2024-04-16T11:20:40.441868Z","shell.execute_reply.started":"2024-04-16T11:20:40.238010Z","shell.execute_reply":"2024-04-16T11:20:40.440608Z"},"trusted":true},"execution_count":95,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[95], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mget_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m emb_database \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((emb_database, emb), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m answers\u001b[38;5;241m.\u001b[39mappend(answer)\n","Cell \u001b[0;32mIn[90], line 4\u001b[0m, in \u001b[0;36mget_answer\u001b[0;34m(model, tokenizer, info_prompt, question)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_answer\u001b[39m(model, tokenizer, info_prompt, question):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Tokenize question\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m info_prompt\u001b[38;5;241m.\u001b[39mformat(question\u001b[38;5;241m=\u001b[39mquestion)\n\u001b[0;32m----> 4\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m()\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(inputs)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Generate output\u001b[39;00m\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'cuda'"],"ename":"AttributeError","evalue":"'list' object has no attribute 'cuda'","output_type":"error"}]},{"cell_type":"markdown","source":"## Старая версия","metadata":{}},{"cell_type":"code","source":"# adapt_model_name = \"IlyaGusev/saiga_mistral_7b_lora\"\n\n# tokenizer = AutoTokenizer.from_pretrained(\n#               adapt_model_name,\n#               trust_remote_code=True)\n\n# tokenizer.pad_token = tokenizer.eos_token\n# device_map = {\"\": 0}\n# model = AutoPeftModelForCausalLM.from_pretrained(\n#             adapt_model_name,\n#             load_in_8bit = True,\n#             device_map=device_map,\n#             torch_dtype=torch.bfloat16\n# )\n\n# model = model.to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2024-04-16T08:41:34.887892Z","iopub.execute_input":"2024-04-16T08:41:34.888338Z","iopub.status.idle":"2024-04-16T08:43:30.866904Z","shell.execute_reply.started":"2024-04-16T08:41:34.888303Z","shell.execute_reply":"2024-04-16T08:43:30.866143Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6336862c968c474a9d3348bf50423a0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c557250fded24dae881d7a333fc21697"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"319a4fbc287a4cab874b127c2ed670ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/96.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb123301e11c4f0d85cda1d009f89b59"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"837e3f1c55f7470195df6218d80133d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/623 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a20ff3f0e8724692a7c3b52b9be1476b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61261988f22a42ef91b6af9b1034b635"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0276a3d87dbc4062b915a651aa0864ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"644293ac694642c8ab9a867aa60451a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00002.bin:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3917f885f83541babee0e24a55656b94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdd3cb27a62046ca94cd6dc9b8ce3dea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/120 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f1549a47d2e41e8b0ea183ff1f6e537"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/54.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"377df56ce4fc4bcc9e92770fd7d1cc43"}},"metadata":{}}]},{"cell_type":"markdown","source":"Сохранение скачанной модели, чтобы какждый раз при старте ноутбука не скачивать","metadata":{}},{"cell_type":"code","source":"OUTPUT_DIR = \"/kaggle/working/tmp\"\nmodel.save_pretrained(OUTPUT_DIR)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T08:43:30.868011Z","iopub.execute_input":"2024-04-16T08:43:30.868456Z","iopub.status.idle":"2024-04-16T08:43:31.240532Z","shell.execute_reply.started":"2024-04-16T08:43:30.868428Z","shell.execute_reply":"2024-04-16T08:43:31.239528Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def get_embedding(sentence):\n    \n    #Mean Pooling - Take attention mask into account for correct averaging\n    def _mean_pooling(model_output, attention_mask):\n        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n\n    # Tokenize sentences\n    encoded_input = sent_tokenizer([sentence], padding=True, truncation=True, return_tensors='pt')\n\n    # Compute token embeddings\n    with torch.no_grad():\n        model_output = sent_model(**encoded_input)\n\n    # Perform pooling\n    sentence_embeddings = _mean_pooling(model_output, encoded_input['attention_mask'])\n\n    # Normalize embeddings\n    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n\n    return sentence_embeddings","metadata":{"execution":{"iopub.status.busy":"2024-04-16T11:05:54.146501Z","iopub.execute_input":"2024-04-16T11:05:54.147436Z","iopub.status.idle":"2024-04-16T11:05:54.154463Z","shell.execute_reply.started":"2024-04-16T11:05:54.147402Z","shell.execute_reply":"2024-04-16T11:05:54.153294Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"answers = []\nemb_database = torch.empty((0, 384), dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T08:43:31.251202Z","iopub.execute_input":"2024-04-16T08:43:31.251541Z","iopub.status.idle":"2024-04-16T08:43:31.261839Z","shell.execute_reply.started":"2024-04-16T08:43:31.251510Z","shell.execute_reply":"2024-04-16T08:43:31.261037Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"texts = pd.read_csv(\"/kaggle/input/zulip-wekan/qa_preproc_wekan.csv\", index_col=False)\ntexts[\"qa\"] = texts['question'] + texts['answer']","metadata":{"execution":{"iopub.status.busy":"2024-04-16T08:43:31.262799Z","iopub.execute_input":"2024-04-16T08:43:31.263057Z","iopub.status.idle":"2024-04-16T08:43:31.327991Z","shell.execute_reply.started":"2024-04-16T08:43:31.263035Z","shell.execute_reply":"2024-04-16T08:43:31.327086Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                              question  \\\n309  Добрый день! Я из проекта 394. На нашей доске ...   \n246  @Влада Леушина , иногда сбрасывание сессии пом...   \n50   Здравствуйте! Назначьте пожалуйста Американова...   \n366  @Техническая поддержка МИЭМ  добрый день, по с...   \n120  @Даниил Колесов , @Александра Шарудилова , @На...   \n\n                                                answer  \\\n309          @Ксения Грязева , добрый день! исправлено   \n246  @Валерия Немна Так из кабинета ссылка введет в...   \n50    @Александр Американов , добрый вечер! Назначили.   \n366  @Андрей Ощепков  Добрый день, приняли Ваш запр...   \n120      @Валерия Немна , спасибо, доска уже появилась   \n\n                                                    qa  \n309  Добрый день! Я из проекта 394. На нашей доске ...  \n246  @Влада Леушина , иногда сбрасывание сессии пом...  \n50   Здравствуйте! Назначьте пожалуйста Американова...  \n366  @Техническая поддержка МИЭМ  добрый день, по с...  \n120  @Даниил Колесов , @Александра Шарудилова , @На...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n      <th>qa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>309</th>\n      <td>Добрый день! Я из проекта 394. На нашей доске ...</td>\n      <td>@Ксения Грязева , добрый день! исправлено</td>\n      <td>Добрый день! Я из проекта 394. На нашей доске ...</td>\n    </tr>\n    <tr>\n      <th>246</th>\n      <td>@Влада Леушина , иногда сбрасывание сессии пом...</td>\n      <td>@Валерия Немна Так из кабинета ссылка введет в...</td>\n      <td>@Влада Леушина , иногда сбрасывание сессии пом...</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>Здравствуйте! Назначьте пожалуйста Американова...</td>\n      <td>@Александр Американов , добрый вечер! Назначили.</td>\n      <td>Здравствуйте! Назначьте пожалуйста Американова...</td>\n    </tr>\n    <tr>\n      <th>366</th>\n      <td>@Техническая поддержка МИЭМ  добрый день, по с...</td>\n      <td>@Андрей Ощепков  Добрый день, приняли Ваш запр...</td>\n      <td>@Техническая поддержка МИЭМ  добрый день, по с...</td>\n    </tr>\n    <tr>\n      <th>120</th>\n      <td>@Даниил Колесов , @Александра Шарудилова , @На...</td>\n      <td>@Валерия Немна , спасибо, доска уже появилась</td>\n      <td>@Даниил Колесов , @Александра Шарудилова , @На...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"f = lambda x : ' '.join(x)\ntext = f(texts_cut['qa']) + \"{question}\\nbot: Вот ответ на ваш вопрос длиной не более 10 слов\"\ninfo_prompt_less10 = PromptTemplate.from_template(text)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T08:43:31.329023Z","iopub.execute_input":"2024-04-16T08:43:31.329314Z","iopub.status.idle":"2024-04-16T08:43:31.335664Z","shell.execute_reply.started":"2024-04-16T08:43:31.329291Z","shell.execute_reply":"2024-04-16T08:43:31.334838Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"len(text)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T08:43:31.338448Z","iopub.execute_input":"2024-04-16T08:43:31.338708Z","iopub.status.idle":"2024-04-16T08:43:31.346542Z","shell.execute_reply.started":"2024-04-16T08:43:31.338686Z","shell.execute_reply":"2024-04-16T08:43:31.345723Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"210189"},"metadata":{}}]},{"cell_type":"markdown","source":"Функция из статьи","metadata":{}},{"cell_type":"code","source":"# def get_answer(model, info_prompt, question):\n    \n#     prompt = info_prompt.format(question=question)   \n#     inputs = tokenizer(prompt, return_tensors=\"pt\")\n#     outputs = model.generate(input_ids=inputs[\"input_ids\"], \n#                             top_p=0.5,\n#                             temperature=0.3,\n#                             attention_mask=inputs[\"attention_mask\"],\n#                             max_new_tokens=100,\n#                             pad_token_id=tokenizer.eos_token_id,\n#                             do_sample=True)\n\n#     output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n#     parsed_answer = output.split(\"Вот ответ на ваш вопрос длиной не более 10 слов:\")[1].strip()\n\n#     if \"bot:\" in parsed_answer:\n#         parsed_answer = parsed_answer.split(\"bot:\")[0].strip()\n\n#     return parsed_answer","metadata":{"execution":{"iopub.status.busy":"2024-04-16T08:32:06.681345Z","iopub.execute_input":"2024-04-16T08:32:06.681776Z","iopub.status.idle":"2024-04-16T08:32:06.688553Z","shell.execute_reply.started":"2024-04-16T08:32:06.681745Z","shell.execute_reply":"2024-04-16T08:32:06.687780Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Переписанная функция из статьи","metadata":{}},{"cell_type":"code","source":"def get_answer(model, tokenizer, info_prompt, question):\n    # Tokenize all questions\n    prompt = info_prompt.format(question=question)\n    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).input_ids.cuda()\n    print(tokenizer.eos_token_id)\n    # Generate output\n    with torch.no_grad():\n        outputs = model.generate(input_ids=inputs, \n                                max_length=128,  # Adjust the max_length as needed\n                                pad_token_id=tokenizer.eos_token_id,\n                                do_sample=True)\n\n    # Decode outputs\n    output_decode = tokenizer.decode(outputs[0], skip_special_tokens=True)\n#     parsed_answer = output_decode.split(\"Вот ответ на ваш вопрос длиной не более 10 слов:\")[1].strip()\n\n#     if \"bot:\" in parsed_answer:\n#         parsed_answer = parsed_answer.split(\"bot:\")[0].strip()\n    parsed_answer = output_decode\n    return parsed_answer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"question = \"Как авторизоваться в векан?\" \nemb = get_embedding(question)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_cos_sim(question):\n    cos_sim = F.cosine_similarity(emb_database, emb, dim=1, eps=1e-8)\n    return cos_sim\n  \nget_cos_sim(question)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answer = get_answer(model, tokenizer, info_prompt_less10, question)\nemb_database = torch.cat((emb_database, emb), 0)\nanswers.append(answer)\nprint(f'Answer from model: {answer}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"questions = [\n    \"Не зачтены часы в карточке в wekan\",\n    \"Не  отображается доска в wekan\",\n    \"Не зачисляются часы в карточке\",\n    \"Руководитель не может проставить часы\",\n    \"Не найдена доска в wekan\",\n    \"Можно ли удалить неверно зачтенную карточку?\",\n    \"Не получается авторизоваться в wekan\"\n            ] ","metadata":{"execution":{"iopub.status.busy":"2024-04-16T09:01:43.022316Z","iopub.execute_input":"2024-04-16T09:01:43.022611Z","iopub.status.idle":"2024-04-16T09:01:43.027420Z","shell.execute_reply.started":"2024-04-16T09:01:43.022586Z","shell.execute_reply":"2024-04-16T09:01:43.026471Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"for q in questions:\n    print(q)\n    emb = get_embedding(q)\n#     answer = get_answer(info_prompt_less10, q)\n#     emb_database = torch.cat((emb_database, emb), 0)\n#     answers.append(answer)\n#     print(f'Answer from model: {answer}')\n    \n    cos_sim = get_cos_sim(q)\n    max_value, max_index = torch.max(get_cos_sim(q), dim=0)\n\n    if max_value > 0.9:\n        answer = answers[max_index]\n        print(f'DATABASE: {answer}')\n    else:\n        answer = get_answer(model, tokenizer, info_prompt_less10, q)\n        emb_database = torch.cat((emb_database, emb), 0)\n        answers.append(answer)\n        print(f'MODEL: {answer}')\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T09:02:10.378193Z","iopub.execute_input":"2024-04-16T09:02:10.378585Z","iopub.status.idle":"2024-04-16T09:02:42.726332Z","shell.execute_reply.started":"2024-04-16T09:02:10.378557Z","shell.execute_reply":"2024-04-16T09:02:42.725315Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"Не зачтены часы в карточке в wekan\nMODEL: Кожакин Кирилл Геннадьевич &lt;kgkozhakin@edu.hse.ru&gt;,\nКозлов Александр Сергеевич &lt;askozlov_13@edu.hse.ru&gt;,\nШаповалов Михаил Вадимович &lt;mvshapovalov@edu.hse.ru&gt;@Александр Подшивалов , теперь все участники присоединены к доске. Шаповалов говорит, что они\n\nНе  отображается доска в wekan\nMODEL: Кожакин Кирилл Геннадьевич &lt;kgkozhakin@edu.hse.ru&gt;,\nКозлов Александр Сергеевич &lt;askozlov_13@edu.hse.ru&gt;,\nШаповалов Михаил Вадимович &lt;mvshapovalov@edu.hse.ru&gt;@Александр Подшивалов , теперь все участники присоединены к доске. Шаповалов говорит, что про\n\nНе зачисляются часы в карточке\nMODEL: Кожакин Кирилл Геннадьевич &lt;kgkozhakin@edu.hse.ru&gt;,\nКозлов Александр Сергеевич &lt;askozlov_13@edu.hse.ru&gt;,\nШаповалов Михаил Вадимович &lt;mvshapovalov@edu.hse.ru&gt;@Александр Подшивалов , теперь все участники присоединены к доске. Шаповалов говорит, что все\n\nРуководитель не может проставить часы\nMODEL: Кожакин Кирилл Геннадьевич &lt;kgkozhakin@edu.hse.ru&gt;,\nКозлов Александр Сергеевич &lt;askozlov_13@edu.hse.ru&gt;,\nШаповалов Михаил Вадимович &lt;mvshapovalov@edu.hse.ru&gt;@Александр Подшивалов , теперь все участники присоединены к доске. Шаповалов говорит, что в\n\nНе найдена доска в wekan\nMODEL: Кожакин Кирилл Геннадьевич &lt;kgkozhakin@edu.hse.ru&gt;,\nКозлов Александр Сергеевич &lt;askozlov_13@edu.hse.ru&gt;,\nШаповалов Михаил Вадимович &lt;mvshapovalov@edu.hse.ru&gt;@Александр Подшивалов , теперь все участники присоединены к доске. Шаповалов говорит, что в\n\nМожно ли удалить неверно зачтенную карточку?\nMODEL: Кожакин Кирилл Геннадьевич &lt;kgkozhakin@edu.hse.ru&gt;,\nКозлов Александр Сергеевич &lt;askozlov_13@edu.hse.ru&gt;,\nШаповалов Михаил Вадимович &lt;mvshapovalov@edu.hse.ru&gt;@Александр Подшивалов , теперь все участники присоединены к доске. Шаповалов говорит, что с\n\nНе получается авторизоваться в wekan\nMODEL: Кожакин Кирилл Геннадьевич &lt;kgkozhakin@edu.hse.ru&gt;,\nКозлов Александр Сергеевич &lt;askozlov_13@edu.hse.ru&gt;,\nШаповалов Михаил Вадимович &lt;mvshapovalov@edu.hse.ru&gt;@Александр Подшивалов , теперь все участники присоединены к доске. Шаповалов говорит, что его\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}